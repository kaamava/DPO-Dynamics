import os
import torch
import json
import argparse
import pandas as pd
import math
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM
import numpy as np
import torch.nn.functional as F

class Selector:
    """åŸºäºç›¸ä¼¼åº¦çš„æ•°æ®é€‰æ‹©å™¨"""
    
    def __init__(self, model_path: str, max_length: int = 512, mode: str = 'entk'):
        self.max_length = max_length
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.mode = mode
        
        print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True
        )
        
        # è®¾ç½®pad_token
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {self.device}")
        print(f"ğŸ§® å½“å‰ç›¸ä¼¼æ€§è®¡ç®—æ¨¡å¼: {self.mode}")
    
    def get_gradient_for_input(self, messages) -> torch.Tensor:
        """è®¡ç®—è¾“å…¥æ¶ˆæ¯åˆ—è¡¨çš„æ¢¯åº¦å‘é‡"""
        self.model.zero_grad()
        try:
            # ç”¨chatæ¨¡æ¿æ ¼å¼åŒ–
            chat_str = self.tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=False
            )
            # åˆ†è¯
            inputs = self.tokenizer(
                chat_str,
                return_tensors="pt",
                truncation=True,
                max_length=self.max_length
            )
            with torch.enable_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                y_hat = torch.mean(logits)
            y_hat.backward()
            gradients = []
            for param in self.model.parameters():
                if param.grad is not None:
                    gradients.append(param.grad.flatten().cpu())
            grad_vector = torch.cat(gradients)
            return grad_vector.detach().clone()
        finally:
            # æ¸…ç†è®¡ç®—å›¾å’Œä¸­é—´å˜é‡
            self.model.zero_grad()
            torch.cuda.empty_cache()
    
    def compute_entk_similarity(self, messages1, messages2) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ¶ˆæ¯åˆ—è¡¨çš„ENTKå†…ç§¯ç›¸ä¼¼æ€§"""
        self.model.train()
        grad1 = self.get_gradient_for_input(messages1)
        grad2 = self.get_gradient_for_input(messages2)
        grad1_norm = grad1.norm().item()
        grad2_norm = grad2.norm().item()
        if grad1_norm == 0 or grad2_norm == 0:
            del grad1, grad2
            torch.cuda.empty_cache()
            return 0.0
        if not torch.isfinite(grad1).all() or not torch.isfinite(grad2).all():
            del grad1, grad2
            torch.cuda.empty_cache()
            return 0.0
        inner_product = torch.dot(grad1, grad2).item()
        if not math.isfinite(inner_product):
            inner_product = 0.0
        del grad1, grad2
        torch.cuda.empty_cache()
        return inner_product

    def compute_hidden_similarity(self, messages1, messages2) -> float:
        """åªå¯¹assistantéƒ¨åˆ†åšmean-poolåå½’ä¸€åŒ–ï¼Œè®¡ç®—ä¸¤ä¸ªchosenå’Œrejectedçš„last layer hidden stateç›¸ä¼¼æ€§"""
        self.model.eval()
        with torch.no_grad():
            def get_assistant_emb(messages):
                # æ‹†åˆ†promptå’Œassistant
                prompt_msgs = [m for m in messages if m.get("role") != "assistant"]
                assistant_msgs = [m for m in messages if m.get("role") == "assistant"]
                if len(assistant_msgs) == 0:
                    return None
                # åªæ”¯æŒæœ€åä¸€æ¡assistantæ¶ˆæ¯
                reply = assistant_msgs[-1]["content"]
                # prompt tokenæ•°
                prompt_ids = self.tokenizer.apply_chat_template(
                    prompt_msgs,
                    add_generation_prompt=True,
                    return_tensors="pt"
                )
                n_prompt = prompt_ids.shape[-1]
                # æ‹¼æ¥assistant
                full_ids = self.tokenizer.apply_chat_template(
                    prompt_msgs + [{"role": "assistant", "content": reply}],
                    add_generation_prompt=False,
                    return_tensors="pt"
                ).to(self.model.device)
                outs = self.model(full_ids, output_hidden_states=True)
                hid = outs.hidden_states[-1][0]  # [seq_len, hidden_dim]
                if n_prompt >= hid.shape[0]:
                    return None
                emb = hid[n_prompt:].mean(0)
                return F.normalize(emb, dim=0)
            emb1 = get_assistant_emb(messages1)
            emb2 = get_assistant_emb(messages2)
            if emb1 is None or emb2 is None:
                return 0.0
            cos_sim = torch.dot(emb1, emb2).item()
            return cos_sim

    def compute_similarity(self, messages1, messages2) -> float:
        if self.mode == 'entk':
            return self.compute_entk_similarity(messages1, messages2)
        elif self.mode == 'last_layer':
            return self.compute_hidden_similarity(messages1, messages2)
        else:
            raise ValueError(f"ç›¸ä¼¼æ€§è®¡ç®—æ¨¡å¼: {self.mode}")

def load_ultrafeedback_data(split="train", max_samples=None):
    """åŠ è½½ultrafeedback_binarizedæ•°æ®é›†"""
    print(f"ğŸ“¥ åŠ è½½æ•°æ®é›†: trl-lib/ultrafeedback_binarized, split={split}")
    
    dataset = load_dataset("trl-lib/ultrafeedback_binarized", split=split)
    
    if max_samples:
        dataset = dataset.select(range(min(max_samples, len(dataset))))
        print(f"ğŸ“Š ä½¿ç”¨æ ·æœ¬æ•°: {len(dataset)}")
    else:
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(dataset)}")
    
    return dataset

def compute_and_save_similarities(dataset, selector, output_file, max_pairs=None):
    mode = selector.mode
    print(f"ğŸ”„ å¼€å§‹è®¡ç®—{mode}ç›¸ä¼¼æ€§å¹¶ä¿å­˜åˆ°: {output_file}")
    results = []
    total_pairs = len(dataset)
    if max_pairs:
        total_pairs = min(max_pairs, total_pairs)
    with tqdm(total=total_pairs, desc=f"è®¡ç®—{mode}ç›¸ä¼¼æ€§") as pbar:
        for i, example in enumerate(dataset):
            if max_pairs and i >= max_pairs:
                break
            chosen = example.get("chosen", [])
            rejected = example.get("rejected", [])
            # ç›´æ¥ç”¨æ¶ˆæ¯åˆ—è¡¨
            messages_chosen = chosen if isinstance(chosen, list) else [chosen]
            messages_rejected = rejected if isinstance(rejected, list) else [rejected]
            try:
                similarity = selector.compute_similarity(messages_chosen, messages_rejected)
                result = {
                    "chosen": chosen,
                    "rejected": rejected,
                    "similarity": similarity,
                    "score_chosen": example.get("score_chosen", ""),
                    "score_rejected": example.get("score_rejected", "")
                }
                results.append(result)
                pbar.set_postfix({
                    f"{mode}_sim": f"{similarity:.4f}",
                    "å½“å‰æ•°é‡": len(results)
                })
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                continue
            pbar.update(1)
    df = pd.DataFrame(results)
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"âœ… è®¡ç®—å®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªæ•°æ®å¯¹")
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    return df

def load_and_filter_from_csv(csv_file, keep_percentage=None, similarity_threshold=None):
    """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®å¹¶è¿›è¡Œè¿‡æ»¤"""
    print(f"ğŸ“¥ ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®: {csv_file}")
    
    df = pd.read_csv(csv_file)
    print(f"ğŸ“Š åŠ è½½äº† {len(df)} ä¸ªæ•°æ®å¯¹")
    
    # æŒ‰ç›¸ä¼¼æ€§æ’åºï¼ˆé™åºï¼‰
    df_sorted = df.sort_values('similarity', ascending=False).reset_index(drop=True)
    
    # æ ¹æ®ç™¾åˆ†æ¯”æˆ–é˜ˆå€¼è¿‡æ»¤æ•°æ®
    if keep_percentage is not None:
        # æŒ‰ç™¾åˆ†æ¯”ä¿ç•™æœ€ç›¸ä¼¼çš„æ•°æ®
        keep_count = int(len(df_sorted) * keep_percentage)
        df_filtered = df_sorted.head(keep_count)
        
        print(f"ğŸ” åŸå§‹æ•°æ®: {len(df_sorted)} å¯¹")
        print(f"ğŸ” ä¿ç•™å‰{keep_percentage*100:.1f}%: {len(df_filtered)} å¯¹")
        print(f"ğŸ” åˆ é™¤æ•°æ®: {len(df_sorted) - len(df_filtered)} å¯¹")
        
        if len(df_filtered) > 0:
            threshold_value = df_filtered['similarity'].iloc[-1]
            print(f"ğŸ” å®é™…é˜ˆå€¼: {threshold_value:.4f}")
    
    elif similarity_threshold is not None:
        # æŒ‰å›ºå®šé˜ˆå€¼è¿‡æ»¤
        df_filtered = df_sorted[df_sorted['similarity'] >= similarity_threshold]
        
        print(f"ğŸ” è¿‡æ»¤å‰: {len(df_sorted)} å¯¹")
        print(f"ğŸ” è¿‡æ»¤å: {len(df_filtered)} å¯¹")
        if len(df_sorted) > 0:
            print(f"ğŸ” è¿‡æ»¤æ¯”ä¾‹: {(len(df_sorted) - len(df_filtered)) / len(df_sorted) * 100:.1f}%")
    
    else:
        df_filtered = df_sorted
    
    if len(df_filtered) > 0:
        similarities = df_filtered['similarity'].values
        print(f"ğŸ“ˆ ä¿ç•™æ•°æ®ç›¸ä¼¼æ€§ç»Ÿè®¡:")
        print(f"   æœ€å¤§å€¼: {similarities.max():.4f}")
        print(f"   æœ€å°å€¼: {similarities.min():.4f}")
        print(f"   å¹³å‡å€¼: {similarities.mean():.4f}")
        print(f"   ä¸­ä½æ•°: {np.median(similarities):.4f}")
    
    return df_filtered

def save_training_dataset(df_filtered, output_dir):
    """å°†è¿‡æ»¤åçš„æ•°æ®ä¿å­˜ä¸ºè®­ç»ƒæ•°æ®é›†æ ¼å¼"""
    print("ğŸ’¾ ä¿å­˜è®­ç»ƒæ•°æ®é›†...")
    
    # ä¿å­˜ä¸ºJSONæ ¼å¼ï¼ˆç”¨äºHuggingFace datasetsï¼‰
    training_data = []
    for _, row in df_filtered.iterrows():
        # é‡æ„ä¸ºåŸå§‹æ•°æ®é›†æ ¼å¼
        training_sample = {
            "chosen": eval(row["chosen"]) if isinstance(row["chosen"], str) else row["chosen"],
            "rejected": eval(row["rejected"]) if isinstance(row["rejected"], str) else row["rejected"],
            "score_chosen": row.get("score_chosen", ""),
            "score_rejected": row.get("score_rejected", ""),
            "similarity": row["similarity"]
        }
        training_data.append(training_sample)
    
    # ä¿å­˜ä¸ºJSON Linesæ ¼å¼ï¼ˆä¾¿äºåŠ è½½ï¼‰
    jsonl_file = output_dir / "filtered_training_data.jsonl"
    with open(jsonl_file, 'w', encoding='utf-8') as f:
        for sample in training_data:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    # ä¿å­˜ä¸ºå•ä¸ªJSONæ–‡ä»¶
    json_file = output_dir / "filtered_training_data.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(training_data, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
    dataset_info = {
        "total_samples": len(training_data),
        "format": "DPO preference dataset",
        "fields": ["chosen", "rejected", "similarity"],
        "similarity_range": {
            "min": float(df_filtered['similarity'].min()),
            "max": float(df_filtered['similarity'].max()),
            "mean": float(df_filtered['similarity'].mean())
        },
        "usage": {
            "load_jsonl": "dataset = load_dataset('json', data_files='filtered_training_data.jsonl')",
            "load_json": "dataset = load_dataset('json', data_files='filtered_training_data.json')"
        }
    }
    
    info_file = output_dir / "dataset_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(dataset_info, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ è®­ç»ƒæ•°æ®å·²ä¿å­˜:")
    print(f"   ğŸ“„ JSONLæ ¼å¼: {jsonl_file}")
    print(f"   ğŸ“„ JSONæ ¼å¼: {json_file}")
    print(f"   ğŸ“„ æ•°æ®é›†ä¿¡æ¯: {info_file}")
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°: {len(training_data)}")
    
    return training_data

def main():
    parser = argparse.ArgumentParser(description="ENTKæ•°æ®é€‰æ‹©å·¥å…·")
    
    parser.add_argument(
        "--model_path",
        type=str,
        default="Qwen/Qwen2.5-0.5B-Instruct",
        help="ç”¨äºè®¡ç®—ENTKçš„æ¨¡å‹è·¯å¾„"
    )
    
    parser.add_argument(
        "--keep_percentage",
        type=float,
        default=None,
        help="ä¿ç•™æœ€ç›¸ä¼¼çš„å‰X%æ•°æ®ï¼Œä¾‹å¦‚0.95è¡¨ç¤ºä¿ç•™å‰95%æ•°æ®"
    )
    
    parser.add_argument(
        "--similarity_threshold",
        type=float,
        default=None,
        help="ENTKç›¸ä¼¼æ€§é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„æ•°æ®å¯¹å°†è¢«è¿‡æ»¤"
    )
    
    parser.add_argument(
        "--max_samples",
        type=int,
        default=-1,
        help="æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆ-1è¡¨ç¤ºå¤„ç†å…¨éƒ¨ï¼‰"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--csv_file",
        type=str,
        default=None,
        help="å·²æœ‰çš„CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œå°†ç›´æ¥ä»æ­¤æ–‡ä»¶åŠ è½½è€Œä¸é‡æ–°è®¡ç®—ï¼‰"
    )
    
    parser.add_argument(
        "--compute_only",
        action="store_true",
        help="åªè®¡ç®—ç›¸ä¼¼æ€§å¹¶ä¿å­˜CSVï¼Œä¸è¿›è¡Œè¿‡æ»¤"
    )
    
    parser.add_argument(
        "--split",
        type=str,
        default="train",
        help="æ•°æ®é›†åˆ†å‰²ï¼ˆtrain/test/validationï¼‰"
    )
    
    parser.add_argument(
        "--random_drop_percentage",
        type=float,
        default=None,
        help="éšæœºä¸¢å¼ƒæ•°æ®çš„æ¯”ä¾‹ï¼ˆå¦‚0.2è¡¨ç¤ºéšæœºä¸¢å¼ƒ20%ï¼‰"
    )
    
    parser.add_argument(
        "--similarity_mode",
        type=str,
        choices=["entk", "last_layer"],
        default=None,
        help="ç›¸ä¼¼åº¦è®¡ç®—æ¨¡å¼ï¼Œå¯é€‰ 'entk' æˆ– 'last_layer'"
    )
    
    args = parser.parse_args()
    
    if args.output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output_dir = f"entk_filtered_data_{timestamp}"
    
    if args.max_samples == -1:
        args.max_samples = None
    
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    print("ğŸ”¬ æ•°æ®ç­›é€‰å·¥å…·")
    print("=" * 60)
    print(f"ğŸ¤– æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ğŸ“ˆ æœ€å¤§æ ·æœ¬æ•°: {args.max_samples if args.max_samples else 'å…¨éƒ¨'}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“š æ•°æ®åˆ†å‰²: {args.split}")

    # å‚æ•°äº’æ–¥æ€§æ£€æŸ¥
    random_drop_valid = args.random_drop_percentage is not None and 0 < args.random_drop_percentage < 1
    similarity_mode_valid = args.similarity_mode is not None
    if random_drop_valid == similarity_mode_valid:
        raise ValueError("Mode Conflict!")

    # 1. éšæœºä¸¢å¼ƒåˆ†æ”¯
    if random_drop_valid:
        print(f"âš ï¸ ä»…åšéšæœºä¸¢å¼ƒ {args.random_drop_percentage*100:.1f}% çš„æ•°æ®ï¼Œä¸è¿›è¡Œæ¨¡å‹æ¨ç†")
        dataset = load_ultrafeedback_data(split=args.split, max_samples=args.max_samples)
        import random
        keep_num = int(len(dataset) * (1 - args.random_drop_percentage))
        keep_indices = sorted(random.sample(range(len(dataset)), keep_num))
        dataset = dataset.select(keep_indices)
        results = []
        for example in dataset:
            result = {
                "chosen": example.get("chosen", []),
                "rejected": example.get("rejected", []),
                "score_chosen": example.get("score_chosen", ""),
                "score_rejected": example.get("score_rejected", "")
            }
            results.append(result)
        df = pd.DataFrame(results)
        csv_file = output_dir / "random_filtered_data.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        print(f"ğŸ’¾ éšæœºä¸¢å¼ƒåæ•°æ®ä¿å­˜åˆ°: {csv_file}")
        # ä¿å­˜ä¸ºjsonl
        jsonl_file = output_dir / "random_filtered_data.jsonl"
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for sample in results:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        # ä¿å­˜ä¸ºjson
        json_file = output_dir / "random_filtered_data.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ è®­ç»ƒæ•°æ®å·²ä¿å­˜:")
        print(f"   ğŸ“„ CSVæ ¼å¼: {csv_file}")
        print(f"   ğŸ“„ JSONLæ ¼å¼: {jsonl_file}")
        print(f"   ğŸ“„ JSONæ ¼å¼: {json_file}")
        print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°: {len(results)}")
        print("ğŸ‰ éšæœºä¸¢å¼ƒæ•°æ®å¤„ç†å®Œæˆ!")
        return

    # 2. åŸºäºç›¸ä¼¼åº¦çš„åˆ†æ”¯
    similarity_mode = args.similarity_mode
    print(f"å½“å‰ç›¸ä¼¼åº¦è®¡ç®—æ¨¡å¼: {similarity_mode}")

    # 2.1 æœ‰csvç›´æ¥åŠ è½½ï¼Œå¦åˆ™åšæ¨ç†ç”Ÿæˆcsv
    if args.csv_file and Path(args.csv_file).exists():
        print("ğŸ“¥ ä»å·²æœ‰CSVæ–‡ä»¶åŠ è½½æ•°æ®...")
        df = pd.read_csv(args.csv_file)
    else:
        print("ğŸ”„ è®¡ç®—ç›¸ä¼¼æ€§...")
        selector = Selector(args.model_path, mode=similarity_mode)
        dataset = load_ultrafeedback_data(split=args.split, max_samples=args.max_samples)
        csv_file = output_dir / "entk_similarities.csv"
        df = compute_and_save_similarities(dataset, selector, csv_file, args.max_samples)

    # 3. åˆ†æ•°è¿‡æ»¤
    if args.keep_percentage is not None or args.similarity_threshold is not None:
        print("\nğŸ” å¼€å§‹è¿‡æ»¤æ•°æ®...")
        df_filtered = load_and_filter_from_csv(csv_file, args.keep_percentage, args.similarity_threshold)
        # ä¿å­˜è¿‡æ»¤åçš„ç»“æœ
        filtered_csv = output_dir / "entk_filtered_data.csv"
        df_filtered.to_csv(filtered_csv, index=False, encoding='utf-8')
        print(f"ğŸ’¾ è¿‡æ»¤åæ•°æ®ä¿å­˜åˆ°: {filtered_csv}")
        # ä¿å­˜ä¸ºè®­ç»ƒæ•°æ®é›†æ ¼å¼
        training_data = save_training_dataset(df_filtered, output_dir)
    else:
        print("âš ï¸ æœªæŒ‡å®šè¿‡æ»¤æ¡ä»¶ï¼Œè·³è¿‡è¿‡æ»¤æ­¥éª¤")
    print("ğŸ‰ æ•°æ®é€‰æ‹©å®Œæˆ!")

if __name__ == "__main__":
    main()